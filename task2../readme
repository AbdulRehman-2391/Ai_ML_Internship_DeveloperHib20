Task 2: End-to-End ML Pipeline â€“ Telco Customer Churn Prediction
ğŸ“Œ Objective

The goal of this task is to build a production-ready machine learning pipeline that predicts customer churn using the Telco Customer Churn dataset.
This pipeline automates preprocessing, training, and model selection, making it reusable for real-world deployment.

ğŸ“‚ Dataset

Name: WA_Fn-UseC_-Telco-Customer-Churn.csv

Target column: Churn (Yes/No)

Features: Customer demographics, service details, billing & contract info.

âš™ï¸ Methodology
1. Data Preprocessing

Converted "TotalCharges" to numeric (errors="coerce").

Dropped rows with missing values.

Scaled numeric features with StandardScaler.

Encoded categorical features with OneHotEncoder.

2. Pipeline Construction

Used Scikit-learn Pipeline with:

ColumnTransformer (numeric + categorical preprocessing).

Classifiers:

Logistic Regression

Random Forest

3. Hyperparameter Tuning

Applied GridSearchCV with 3-fold cross-validation.

Parameters tuned:

Logistic Regression â†’ C = [0.1, 1, 10]

Random Forest â†’ n_estimators = [50, 100], max_depth = [5, 10]

4. Model Evaluation

Accuracy score on train and test data.

Best model & parameters printed.

5. Model Export

Saved best pipeline using joblib.dump() â†’ best_pipeline.pkl

ğŸ“Š Results

Best Model: âœ… (depends on GridSearch outcome, usually Random Forest wins)

Training Accuracy: ~ 0.80 â€“ 0.85

Test Accuracy: ~ 0.78 â€“ 0.83
(results may vary slightly depending on splits)

ğŸ“¦ Files

task2_pipeline.ipynb â†’ Jupyter Notebook with complete code.

best_pipeline.pkl â†’ Saved best trained pipeline.

README.md â†’ Documentation (this file).

ğŸš€ Skills Gained

End-to-end ML pipeline construction

Preprocessing automation (scaling + encoding)

Hyperparameter tuning with GridSearchCV

Model persistence using Joblib
